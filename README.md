
# 人工智能实验报告：基于字的二元模型的拼音输入法
Simple realization of pinyin input method
## 问题描述
&emsp;本次作业要求实现一个基于字的二元模型的简单的汉语拼音输入法，即实现从全拼到字串内容的转换  
&emsp;&emsp;输入：'ren gong zhi neng'  
&emsp;&emsp;输出：'人工智能'  
  
## 算法原理与实现过程
### 动态规划：viterbi算法
&emsp;讲全拼转换为汉字的所有可能解构造为一张有向图，第i层对应第i个字。通过迭代计算可以得到起点到每一层的每个节点的最短路径。在该问题中，即第1个字到第i个字构成句子的最大可能解。因此，最终计算到最后一个字时，取最大概率的路径为全拼对应的字串序列。  
&emsp;其中从第一个字到最后一个字(句子S)与全拼(O)正确对应的概率为P(S|O)=P(S)P(O|S)/P(O)。由于P(O)为常量，P(O|S)≈1，P(S)=$\prod_1^n P(wi|w1...wi-1)$。使用二元语法时，P(S)=$\prod_1^n P(wi|wi-1)$。由于语料库中每个字、词分布很稀疏，最终求得P很小可能导致下溢，因此对其取对数，等价于最终目标是得到min$\prod_1^n -log(P(wi|wi-1))$。  
  
### 实现过程（pinyin2hanzi.py，spyder分块执行）
* In[1] 生成语料库 读取新浪新闻文件2016-02.txt，根据标点符号分句得到语料库 存储文件
* In[2] In[3] In[4] 扫描语料库获得单字频次与二元组频次（以两层字典形式存储便于搜索） 存储文件
* In[5] In[6] 根据频率计算估计单字概率与二元组的条件概率 存储文件
* In[7] 将拼音汉字表转存为字典格式
* In[8] 算法实现，全拼转换为字串，对应pinyin.exe中的内容
&emsp;定义图结构，初始化得到全拼对应的图和所有节点（用于记录路径）
&emsp;遍历每一层计算最短路径。为避免p(wi|wi-1)=0取对数报错，进行平滑处理。若wi未在语料库中出现（p(wi)=0）,min_score=inf。
&emsp;依据最后一层最小值节点回溯路径得到最终字串结果
* In[9] 调参：λ
* In[10] 计算准确率
  
## 实验结果
### 调参结果
使用input.txt进行测试，得到结果与output.txt比对。字准确率高于句子准确率。由于样本较少，得到字准确率、句子准确率结果均较高，随λ增大而增大并趋于平缓。  
![test_accuracy of different λ](https://github.com/h-xixixixix/Pinyin2Hanzi_vertibi/blob/main/src/test_accuracy_%CE%BB_input.png)   
使用更多样本[input_2.txt](https://github.com/AlexFxw/simple-pinyin-input/blob/master/data/input.txt)，得到训练结果句子准确率明显降低，准确率随λ增大而增大并趋于平缓。  
最终使用λ=0.99  
![test_accuracy of different λ](https://github.com/h-xixixixix/Pinyin2Hanzi_vertibi/blob/main/src/test_accuracy_%CE%BB_input.png)  
  
### 输出结果
1. input.txt 句子准确率0.75，字准确率0.96  
input: 
* qing hua da xue ji suan ji xi
* wo shang xue qu le
* jin tian hui jia bi jiao wan
* liang hui zai bei jing zhao kai  
output:
* 清华大学计算机系
* 我上学去了
* 今天回家比较[完]
* 两会在北京召开
2. input_2.txt 句子准确率0.31683168316831684，字准确率0.8  
部分正确结果：  
&emsp;('社会最大的最恶', ' 输出:社会最大的最恶'),   
&emsp;('大家喜欢听的个多种多样', ' 输出:大家喜欢听的个多种多样'),  
&emsp;('你会获了我的崇拜', ' 输出:你会获了我的崇拜'),   
&emsp;('我们将挑选人最多的一个时间', ' 输出:我们将挑选人最多的一个时间'),  
&emsp;('可是有能怎么办呢', ' 输出:可是有能怎么办呢'),  
&emsp;('灵谷先生', ' 输出:灵谷先生'),  
&emsp;('我说', ' 输出:我说'),   
&emsp;('我有一个苹果', ' 输出:我有一个苹果')  
部分错误结果：  
&emsp;('虽然已经解决了建立新技分方法的首要问题', ' 输出:虽然已经解决了[简历]新[几]分方法的首要问题'),  
&emsp;('建立了交易办机上的策独立伦', ' 输出:建立了交易办机上的[策都理论]'),  
&emsp;('后面我们将成具有这种形之的函数为可测函数', ' 输出:后面我们将成具有这种[姓氏]的[含数]为[可测含数]'),  
&emsp;('下面引入可测函数的概念', ' 输出:下面引入[课测含数]的概念'),  
&emsp;('可测函数的有限可家行', ' 输出:可测含数的有限[可嘉兴]'),  
&emsp;('你会改把', ' 输出:你会改[八]')  
&emsp;('小胖胖有一个大肚皮', ' 输出:小胖胖有一个大[都被]'),  
&emsp;('为了抗议苏联入侵阿富汗', ' 输出:为了抗议[速连]入侵阿富汗'),  
&emsp;('我将不顾一切的来到这第方', ' 输出:我将不顾一切地来到这[地方]')  
  
从这些结果中可以看到：  
* 该输入法对于一些使用频率高的字词搭配效果较好。其实原样本中也存在一些错误，而输出结果实际上进行了纠正如“理论”“地方”。
* 该输入法受语料库限制较大。其对于专业词汇的识别能力较弱如“可测函数”“可加性”等。因此在某些专业领域的输入搜索需要专业语料库的补充，语料库的准确性和体量对于输入法准确性可以产生较大的影响。
* 二元模型下，只考虑了与前一个字的条件概率，例如“可加性”，若只考虑二元语法，“可嘉”“嘉兴”确实是我们生活中常见的用法，但若放大范围，“可嘉兴”使用的频率应该远不如“可加性”，甚至再放大范围，考虑“有限可加性”可能能更精准。  
* 维特比算法下，只考虑了前缀的概率。例如“具有这种姓氏”看上去没有什么问题，但结合后面的内容“函数”“可测函数”，显然这个结果是不正确的。同时，考虑“姓氏的含数”也是不正确的。

## 改进方案
&emsp;基于以上分析，针对语料库限制，若编写专业的输入法，则需使用更多专业语料库进行训练；若编写普遍适用的输入法，则应增大语料库提量。针对二元模型的局限性，可以利用三元、四元模型进行补充。针对维特比算法只考虑前缀的问题，可以考虑借鉴神经网络的反向传播方法对算法进行优化。  
&emsp;同时，用户使用输入法的过程也是对语料库进行补充的过程，可以根据用户每次的输入对语料库、概率数据进行更新，从而实现更加个性化、精准的结果。
